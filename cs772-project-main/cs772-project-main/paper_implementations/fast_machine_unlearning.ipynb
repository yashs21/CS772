{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://github.com/vikram2000b/Fast-Machine-Unlearning/blob/main/Machine%20Unlearning.ipynb ","metadata":{}},{"cell_type":"markdown","source":"# Machine Unlearning","metadata":{}},{"cell_type":"code","source":"# import required libraries\nimport numpy as np\nimport tarfile\nimport os\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as tt\nfrom torchvision.models import resnet18\n\ntorch.manual_seed(100)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T18:53:49.415851Z","iopub.execute_input":"2024-03-28T18:53:49.416316Z","iopub.status.idle":"2024-03-28T18:53:55.651446Z","shell.execute_reply.started":"2024-03-28T18:53:49.416289Z","shell.execute_reply":"2024-03-28T18:53:55.650445Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7b0c64ea78d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Helper Functions","metadata":{}},{"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\ndef training_step(model, batch):\n    images, labels = batch\n    images, labels = images.to(device), labels.to(device)\n    out = model(images)                  \n    loss = F.cross_entropy(out, labels) \n    return loss\n\ndef validation_step(model, batch):\n    images, labels = batch\n    images, labels = images.to(device), labels.to(device)\n    out = model(images)                    \n    loss = F.cross_entropy(out, labels)   \n    acc = accuracy(out, labels)\n    return {'Loss': loss.detach(), 'Acc': acc}\n\ndef validation_epoch_end(model, outputs):\n    batch_losses = [x['Loss'] for x in outputs]\n    epoch_loss = torch.stack(batch_losses).mean()   \n    batch_accs = [x['Acc'] for x in outputs]\n    epoch_acc = torch.stack(batch_accs).mean()      \n    return {'Loss': epoch_loss.item(), 'Acc': epoch_acc.item()}\n\ndef epoch_end(model, epoch, result):\n    print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n        epoch, result['lrs'][-1], result['train_loss'], result['Loss'], result['Acc']))\n    \ndef distance(model,model0):\n    distance=0\n    normalization=0\n    for (k, p), (k0, p0) in zip(model.named_parameters(), model0.named_parameters()):\n        space='  ' if 'bias' in k else ''\n        current_dist=(p.data0-p0.data0).pow(2).sum().item()\n        current_norm=p.data0.pow(2).sum().item()\n        distance+=current_dist\n        normalization+=current_norm\n    print(f'Distance: {np.sqrt(distance)}')\n    print(f'Normalized Distance: {1.0*np.sqrt(distance/normalization)}')\n    return 1.0*np.sqrt(distance/normalization)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T18:53:55.653302Z","iopub.execute_input":"2024-03-28T18:53:55.654126Z","iopub.status.idle":"2024-03-28T18:53:55.666483Z","shell.execute_reply.started":"2024-03-28T18:53:55.654092Z","shell.execute_reply":"2024-03-28T18:53:55.665501Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [validation_step(model, batch) for batch in val_loader]\n    return validation_epoch_end(model, outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n\n    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n    \n    for epoch in range(epochs): \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = training_step(model, batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            lrs.append(get_lr(optimizer))\n            \n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        epoch_end(model, epoch, result)\n        history.append(result)\n        sched.step(result['Loss'])\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-03-28T18:53:55.667767Z","iopub.execute_input":"2024-03-28T18:53:55.668140Z","iopub.status.idle":"2024-03-28T18:53:55.679417Z","shell.execute_reply.started":"2024-03-28T18:53:55.668109Z","shell.execute_reply":"2024-03-28T18:53:55.678686Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Train/Load the Model","metadata":{}},{"cell_type":"markdown","source":"### load the dataset","metadata":{}},{"cell_type":"code","source":"# Dowload the dataset\ndataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\ndownload_url(dataset_url, '.')\n\n# Extract from archive\nwith tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n    tar.extractall(path='./data')\n    \n# Look into the data directory\ndata_dir = './data/cifar10'\nprint(os.listdir(data_dir))\nclasses = os.listdir(data_dir + \"/train\")\nprint(classes)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T18:53:55.681354Z","iopub.execute_input":"2024-03-28T18:53:55.681682Z","iopub.status.idle":"2024-03-28T18:54:18.693048Z","shell.execute_reply.started":"2024-03-28T18:53:55.681658Z","shell.execute_reply":"2024-03-28T18:54:18.692209Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz to ./cifar10.tgz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 135107811/135107811 [00:08<00:00, 16013484.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"['test', 'train']\n['horse', 'dog', 'automobile', 'truck', 'cat', 'frog', 'bird', 'airplane', 'deer', 'ship']\n","output_type":"stream"}]},{"cell_type":"code","source":"transform_train = tt.Compose([\n    tt.ToTensor(),\n    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = tt.Compose([\n    tt.ToTensor(),\n    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-03-28T18:54:18.694031Z","iopub.execute_input":"2024-03-28T18:54:18.694423Z","iopub.status.idle":"2024-03-28T18:54:18.700169Z","shell.execute_reply.started":"2024-03-28T18:54:18.694395Z","shell.execute_reply":"2024-03-28T18:54:18.699151Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_ds = ImageFolder(data_dir+'/train', transform_train)\nvalid_ds = ImageFolder(data_dir+'/test', transform_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T18:54:18.701481Z","iopub.execute_input":"2024-03-28T18:54:18.702046Z","iopub.status.idle":"2024-03-28T18:54:18.977590Z","shell.execute_reply.started":"2024-03-28T18:54:18.702012Z","shell.execute_reply":"2024-03-28T18:54:18.976686Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"batch_size = 256\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\nvalid_dl = DataLoader(valid_ds, batch_size*2, num_workers=3, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T18:54:18.978685Z","iopub.execute_input":"2024-03-28T18:54:18.978931Z","iopub.status.idle":"2024-03-28T18:54:18.983850Z","shell.execute_reply.started":"2024-03-28T18:54:18.978910Z","shell.execute_reply":"2024-03-28T18:54:18.982972Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Train and save the model","metadata":{}},{"cell_type":"code","source":"device = \"cuda:0\"\nmodel = resnet18(num_classes = 10).to(device = device)\n\nepochs = 40\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","metadata":{"execution":{"iopub.status.busy":"2024-03-28T18:54:18.985070Z","iopub.execute_input":"2024-03-28T18:54:18.985403Z","iopub.status.idle":"2024-03-28T18:54:19.419566Z","shell.execute_reply.started":"2024-03-28T18:54:18.985375Z","shell.execute_reply":"2024-03-28T18:54:19.418548Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)\n\ntorch.save(model.state_dict(), \"ResNET18_CIFAR10_ALL_CLASSES.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-03-28T18:54:19.420809Z","iopub.execute_input":"2024-03-28T18:54:19.421119Z","iopub.status.idle":"2024-03-28T19:02:51.573454Z","shell.execute_reply.started":"2024-03-28T18:54:19.421093Z","shell.execute_reply":"2024-03-28T19:02:51.572282Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch [0], last_lr: 0.01000, train_loss: 1.8275, val_loss: 1.5589, val_acc: 0.4517\nEpoch [1], last_lr: 0.01000, train_loss: 1.3337, val_loss: 1.2530, val_acc: 0.5615\nEpoch [2], last_lr: 0.01000, train_loss: 1.1043, val_loss: 1.1683, val_acc: 0.5815\nEpoch [3], last_lr: 0.01000, train_loss: 0.9457, val_loss: 1.1067, val_acc: 0.6148\nEpoch [4], last_lr: 0.01000, train_loss: 0.8569, val_loss: 0.9355, val_acc: 0.6767\nEpoch [5], last_lr: 0.01000, train_loss: 0.7891, val_loss: 0.9199, val_acc: 0.6757\nEpoch [6], last_lr: 0.01000, train_loss: 0.7428, val_loss: 0.9799, val_acc: 0.6729\nEpoch [7], last_lr: 0.01000, train_loss: 0.6992, val_loss: 0.8524, val_acc: 0.7087\nEpoch [8], last_lr: 0.01000, train_loss: 0.6682, val_loss: 0.8724, val_acc: 0.7061\nEpoch [9], last_lr: 0.01000, train_loss: 0.6446, val_loss: 0.8603, val_acc: 0.7090\nEpoch [10], last_lr: 0.01000, train_loss: 0.6179, val_loss: 0.8086, val_acc: 0.7303\nEpoch [11], last_lr: 0.01000, train_loss: 0.5919, val_loss: 0.7980, val_acc: 0.7316\nEpoch [12], last_lr: 0.01000, train_loss: 0.5797, val_loss: 0.9296, val_acc: 0.6908\nEpoch [13], last_lr: 0.01000, train_loss: 0.5613, val_loss: 0.8742, val_acc: 0.7125\nEpoch [14], last_lr: 0.01000, train_loss: 0.5477, val_loss: 0.7842, val_acc: 0.7363\nEpoch [15], last_lr: 0.01000, train_loss: 0.5345, val_loss: 0.7722, val_acc: 0.7377\nEpoch [16], last_lr: 0.01000, train_loss: 0.5243, val_loss: 0.8440, val_acc: 0.7216\nEpoch [17], last_lr: 0.01000, train_loss: 0.5078, val_loss: 0.8721, val_acc: 0.7132\nEpoch [18], last_lr: 0.01000, train_loss: 0.5008, val_loss: 0.8171, val_acc: 0.7280\nEpoch [19], last_lr: 0.01000, train_loss: 0.4869, val_loss: 0.7965, val_acc: 0.7402\nEpoch 00020: reducing learning rate of group 0 to 5.0000e-03.\nEpoch [20], last_lr: 0.00500, train_loss: 0.3350, val_loss: 0.7546, val_acc: 0.7607\nEpoch [21], last_lr: 0.00500, train_loss: 0.2780, val_loss: 0.8515, val_acc: 0.7457\nEpoch [22], last_lr: 0.00500, train_loss: 0.2784, val_loss: 0.8703, val_acc: 0.7539\nEpoch [23], last_lr: 0.00500, train_loss: 0.2605, val_loss: 0.8754, val_acc: 0.7519\nEpoch [24], last_lr: 0.00500, train_loss: 0.2453, val_loss: 0.9273, val_acc: 0.7438\nEpoch 00025: reducing learning rate of group 0 to 2.5000e-03.\nEpoch [25], last_lr: 0.00250, train_loss: 0.1229, val_loss: 0.9366, val_acc: 0.7632\nEpoch [26], last_lr: 0.00250, train_loss: 0.0661, val_loss: 1.0585, val_acc: 0.7652\nEpoch [27], last_lr: 0.00250, train_loss: 0.0724, val_loss: 1.1720, val_acc: 0.7584\nEpoch [28], last_lr: 0.00250, train_loss: 0.0976, val_loss: 1.1160, val_acc: 0.7610\nEpoch 00029: reducing learning rate of group 0 to 1.2500e-03.\nEpoch [29], last_lr: 0.00125, train_loss: 0.0400, val_loss: 1.1264, val_acc: 0.7695\nEpoch [30], last_lr: 0.00125, train_loss: 0.0143, val_loss: 1.1720, val_acc: 0.7690\nEpoch [31], last_lr: 0.00125, train_loss: 0.0076, val_loss: 1.2286, val_acc: 0.7703\nEpoch [32], last_lr: 0.00125, train_loss: 0.0051, val_loss: 1.2729, val_acc: 0.7692\nEpoch 00033: reducing learning rate of group 0 to 6.2500e-04.\nEpoch [33], last_lr: 0.00063, train_loss: 0.0034, val_loss: 1.2785, val_acc: 0.7693\nEpoch [34], last_lr: 0.00063, train_loss: 0.0024, val_loss: 1.3015, val_acc: 0.7675\nEpoch [35], last_lr: 0.00063, train_loss: 0.0022, val_loss: 1.3184, val_acc: 0.7692\nEpoch [36], last_lr: 0.00063, train_loss: 0.0021, val_loss: 1.3316, val_acc: 0.7695\nEpoch 00037: reducing learning rate of group 0 to 3.1250e-04.\nEpoch [37], last_lr: 0.00031, train_loss: 0.0017, val_loss: 1.3375, val_acc: 0.7706\nEpoch [38], last_lr: 0.00031, train_loss: 0.0015, val_loss: 1.3536, val_acc: 0.7704\nEpoch [39], last_lr: 0.00031, train_loss: 0.0014, val_loss: 1.3431, val_acc: 0.7699\nCPU times: user 4min 33s, sys: 18.2 s, total: 4min 52s\nWall time: 8min 32s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Testing the Model","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"))\nhistory = [evaluate(model, valid_dl)]\nhistory","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:02:51.577829Z","iopub.execute_input":"2024-03-28T19:02:51.578156Z","iopub.status.idle":"2024-03-28T19:02:53.806386Z","shell.execute_reply.started":"2024-03-28T19:02:51.578126Z","shell.execute_reply":"2024-03-28T19:02:53.805319Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[{'Loss': 1.3431131839752197, 'Acc': 0.7699276208877563}]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Unlearning","metadata":{}},{"cell_type":"code","source":"# defining the noise structure\nclass Noise(nn.Module):\n    def __init__(self, *dim):\n        super().__init__()\n        self.noise = torch.nn.Parameter(torch.randn(*dim), requires_grad = True)\n        \n    def forward(self):\n        return self.noise","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:02:53.807650Z","iopub.execute_input":"2024-03-28T19:02:53.807952Z","iopub.status.idle":"2024-03-28T19:02:53.813729Z","shell.execute_reply.started":"2024-03-28T19:02:53.807925Z","shell.execute_reply":"2024-03-28T19:02:53.812852Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# list of all classes\nclasses = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n# classes which are required to un-learn\nclasses_to_forget = [0, 2]","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:02:53.814768Z","iopub.execute_input":"2024-03-28T19:02:53.815016Z","iopub.status.idle":"2024-03-28T19:02:53.825381Z","shell.execute_reply.started":"2024-03-28T19:02:53.814995Z","shell.execute_reply":"2024-03-28T19:02:53.824574Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# classwise list of samples\nnum_classes = 10\nclasswise_train = {}\nfor i in range(num_classes):\n    classwise_train[i] = []\n\nfor img, label in train_ds:\n    classwise_train[label].append((img, label))\n    \nclasswise_test = {}\nfor i in range(num_classes):\n    classwise_test[i] = []\n\nfor img, label in valid_ds:\n    classwise_test[label].append((img, label))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:02:53.826529Z","iopub.execute_input":"2024-03-28T19:02:53.826874Z","iopub.status.idle":"2024-03-28T19:03:19.782225Z","shell.execute_reply.started":"2024-03-28T19:02:53.826812Z","shell.execute_reply":"2024-03-28T19:03:19.781415Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# getting some samples from retain classes\nnum_samples_per_class = 1000\n\nretain_samples = []\nfor i in range(len(classes)):\n    if classes[i] not in classes_to_forget:\n        retain_samples += classwise_train[i][:num_samples_per_class]\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:03:19.783339Z","iopub.execute_input":"2024-03-28T19:03:19.783631Z","iopub.status.idle":"2024-03-28T19:03:19.788954Z","shell.execute_reply.started":"2024-03-28T19:03:19.783607Z","shell.execute_reply":"2024-03-28T19:03:19.788018Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# retain validation set\nretain_valid = []\nfor cls in range(num_classes):\n    if cls not in classes_to_forget:\n        for img, label in classwise_test[cls]:\n            retain_valid.append((img, label))\n            \n# forget validation set\nforget_valid = []\nfor cls in range(num_classes):\n    if cls in classes_to_forget:\n        for img, label in classwise_test[cls]:\n            forget_valid.append((img, label))\n            \nforget_valid_dl = DataLoader(forget_valid, batch_size, num_workers=3, pin_memory=True)\nretain_valid_dl = DataLoader(retain_valid, batch_size*2, num_workers=3, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:03:19.790254Z","iopub.execute_input":"2024-03-28T19:03:19.790700Z","iopub.status.idle":"2024-03-28T19:03:19.809237Z","shell.execute_reply.started":"2024-03-28T19:03:19.790671Z","shell.execute_reply":"2024-03-28T19:03:19.808507Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Training the Noise","metadata":{}},{"cell_type":"code","source":"# loading the model\nmodel = resnet18(num_classes = 10).to(device = device)\nmodel.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:03:19.810200Z","iopub.execute_input":"2024-03-28T19:03:19.810443Z","iopub.status.idle":"2024-03-28T19:03:20.081042Z","shell.execute_reply.started":"2024-03-28T19:03:19.810423Z","shell.execute_reply":"2024-03-28T19:03:20.080117Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\nnoises = {}\nfor cls in classes_to_forget:\n    print(\"Optiming loss for class {}\".format(cls))\n    noises[cls] = Noise(batch_size, 3, 32, 32).cuda()\n    opt = torch.optim.Adam(noises[cls].parameters(), lr = 0.1)\n\n    num_epochs = 5\n    num_steps = 8\n    class_label = cls\n    for epoch in range(num_epochs):\n        total_loss = []\n        for batch in range(num_steps):\n            inputs = noises[cls]()\n            labels = torch.zeros(batch_size).cuda()+class_label\n            outputs = model(inputs)\n            loss = -F.cross_entropy(outputs, labels.long()) + 0.1*torch.mean(torch.sum(torch.square(inputs), [1, 2, 3]))\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            total_loss.append(loss.cpu().detach().numpy())\n        print(\"Loss: {}\".format(np.mean(total_loss)))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:03:20.082201Z","iopub.execute_input":"2024-03-28T19:03:20.082474Z","iopub.status.idle":"2024-03-28T19:03:23.296540Z","shell.execute_reply.started":"2024-03-28T19:03:20.082451Z","shell.execute_reply":"2024-03-28T19:03:23.295737Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Optiming loss for class 0\nLoss: 192.14974975585938\nLoss: 41.48612976074219\nLoss: 0.3930782079696655\nLoss: -7.671341896057129\nLoss: -11.172962188720703\nOptiming loss for class 2\nLoss: 192.119140625\nLoss: 41.8316535949707\nLoss: 1.151537537574768\nLoss: -6.660273551940918\nLoss: -10.079046249389648\nCPU times: user 3.16 s, sys: 18.1 ms, total: 3.18 s\nWall time: 3.21 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Impair Step","metadata":{}},{"cell_type":"code","source":"%%time\n\nbatch_size = 256\nnoisy_data = []\nnum_batches = 20\nclass_num = 0\n\nfor cls in classes_to_forget:\n    for i in range(num_batches):\n        batch = noises[cls]().cpu().detach()\n        for i in range(batch[0].size(0)):\n            noisy_data.append((batch[i], torch.tensor(class_num)))\n\nother_samples = []\nfor i in range(len(retain_samples)):\n    other_samples.append((retain_samples[i][0].cpu(), torch.tensor(retain_samples[i][1])))\nnoisy_data += other_samples\nnoisy_loader = torch.utils.data.DataLoader(noisy_data, batch_size=256, shuffle = True)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.02)\n\n\nfor epoch in range(1):  \n    model.train(True)\n    running_loss = 0.0\n    running_acc = 0\n    for i, data in enumerate(noisy_loader):\n        inputs, labels = data\n        inputs, labels = inputs.cuda(),torch.tensor(labels).cuda()\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = F.cross_entropy(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item() * inputs.size(0)\n        out = torch.argmax(outputs.detach(),dim=1)\n        assert out.shape==labels.shape\n        running_acc += (labels==out).sum().item()\n    print(f\"Train loss {epoch+1}: {running_loss/len(train_ds)},Train Acc:{running_acc*100/len(train_ds)}%\")","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:03:23.297720Z","iopub.execute_input":"2024-03-28T19:03:23.298391Z","iopub.status.idle":"2024-03-28T19:03:24.880835Z","shell.execute_reply.started":"2024-03-28T19:03:23.298357Z","shell.execute_reply":"2024-03-28T19:03:24.879859Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"<timed exec>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","output_type":"stream"},{"name":"stdout","text":"Train loss 1: 0.15691097155570985,Train Acc:11.702%\nCPU times: user 1.49 s, sys: 69.4 ms, total: 1.56 s\nWall time: 1.57 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Performance after Impair Step","metadata":{}},{"cell_type":"code","source":"print(\"Performance of Standard Forget Model on Forget Class\")\nhistory = [evaluate(model, forget_valid_dl)]\nprint(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\nprint(\"Loss: {}\".format(history[0][\"Loss\"]))\n\nprint(\"Performance of Standard Forget Model on Retain Class\")\nhistory = [evaluate(model, retain_valid_dl)]\nprint(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\nprint(\"Loss: {}\".format(history[0][\"Loss\"]))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:03:24.882000Z","iopub.execute_input":"2024-03-28T19:03:24.882320Z","iopub.status.idle":"2024-03-28T19:03:25.747118Z","shell.execute_reply.started":"2024-03-28T19:03:24.882297Z","shell.execute_reply":"2024-03-28T19:03:25.745892Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Performance of Standard Forget Model on Forget Class\nAccuracy: 1.416015625\nLoss: 9.020174026489258\nPerformance of Standard Forget Model on Retain Class\nAccuracy: 64.38964605331421\nLoss: 1.0186243057250977\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Repair Step","metadata":{}},{"cell_type":"code","source":"%%time\n\nheal_loader = torch.utils.data.DataLoader(other_samples, batch_size=256, shuffle = True)\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n\n\nfor epoch in range(1):  \n    model.train(True)\n    running_loss = 0.0\n    running_acc = 0\n    for i, data in enumerate(heal_loader):\n        inputs, labels = data\n        inputs, labels = inputs.cuda(),torch.tensor(labels).cuda()\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = F.cross_entropy(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item() * inputs.size(0)\n        out = torch.argmax(outputs.detach(),dim=1)\n        assert out.shape==labels.shape\n        running_acc += (labels==out).sum().item()\n    print(f\"Train loss {epoch+1}: {running_loss/len(train_ds)},Train Acc:{running_acc*100/len(train_ds)}%\")","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:03:25.748578Z","iopub.execute_input":"2024-03-28T19:03:25.748926Z","iopub.status.idle":"2024-03-28T19:03:27.103507Z","shell.execute_reply.started":"2024-03-28T19:03:25.748898Z","shell.execute_reply":"2024-03-28T19:03:27.102567Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"<timed exec>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","output_type":"stream"},{"name":"stdout","text":"Train loss 1: 0.08834257461547852,Train Acc:12.852%\nCPU times: user 1.33 s, sys: 16.1 ms, total: 1.35 s\nWall time: 1.35 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Performance after Repair Step","metadata":{}},{"cell_type":"code","source":"print(\"Performance of Standard Forget Model on Forget Class\")\nhistory = [evaluate(model, forget_valid_dl)]\nprint(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\nprint(\"Loss: {}\".format(history[0][\"Loss\"]))\n\nprint(\"Performance of Standard Forget Model on Retain Class\")\nhistory = [evaluate(model, retain_valid_dl)]\nprint(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\nprint(\"Loss: {}\".format(history[0][\"Loss\"]))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T19:03:27.104502Z","iopub.execute_input":"2024-03-28T19:03:27.104761Z","iopub.status.idle":"2024-03-28T19:03:27.815827Z","shell.execute_reply.started":"2024-03-28T19:03:27.104730Z","shell.execute_reply":"2024-03-28T19:03:27.814672Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Performance of Standard Forget Model on Forget Class\nAccuracy: 0.0\nLoss: 11.502439498901367\nPerformance of Standard Forget Model on Retain Class\nAccuracy: 73.96240234375\nLoss: 0.7647278904914856\n","output_type":"stream"}]}]}